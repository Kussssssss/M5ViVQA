{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb86df52",
   "metadata": {},
   "source": [
    "# Chạy thực nghiệm dự án ViT5‑VQA trên bộ dữ liệu OpenViVQA\n",
    "\n",
    "Notebook này hướng dẫn cách clone repo `M5ViVQA`, cài đặt các phụ thuộc cần thiết,\n",
    "chuẩn bị dữ liệu và huấn luyện mô hình ViT5‑VQA (bao gồm cả biến thể có MoE) trên\n",
    "bộ dữ liệu OpenViVQA. Các bước được thiết kế để bạn có thể chạy trên nền tảng\n",
    "[Kaggle Notebook](https://www.kaggle.com/) với GPU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221a773c",
   "metadata": {},
   "source": [
    "## 2. Clone repository và chuẩn bị dự án\n",
    "\n",
    "Chúng ta sẽ clone toàn bộ repository `M5ViVQA` từ GitHub và chuyển vào thư mục\n",
    "làm việc. Nếu bạn đã fork dự án, hãy thay đổi URL cho phù hợp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416b4d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repo (chứa toàn bộ mã nguồn tổ chức lại)\n",
    "!git clone https://github.com/Kussssssss/M5ViVQA.git\n",
    "%cd M5ViVQA\n",
    "\n",
    "# Cài đặt các thư viện dựa trên requirements.txt\n",
    "%pip install --quiet -r requirements.txt\n",
    "\n",
    "# Hiển thị cấu trúc thư mục để tham khảo\n",
    "!ls -R . | sed -n '1,200p'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf3c577",
   "metadata": {},
   "source": [
    "## 3. Tải bộ dữ liệu OpenViVQA\n",
    "\n",
    "Dự án đi kèm script `scripts/download_data.py` để tải và giải nén bộ dữ liệu\n",
    "OpenViVQA từ Google Drive. Bạn có thể chạy script này như sau. Hãy đảm bảo\n",
    "bạn có đủ dung lượng lưu trữ (~2 GB) và kết nối internet.\n",
    "\n",
    "Ngoài ra, nếu bạn muốn tải dữ liệu trực tiếp qua Kaggle API, hãy chỉnh sửa\n",
    "phần này cho phù hợp (ví dụ: `kaggle datasets download ...`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67ce3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sử dụng script mới để tự động tải dữ liệu OpenViVQA từ Google Drive\n",
    "!python scripts/download_data_openvivqa.py\n",
    "\n",
    "# Sao chép dữ liệu ra thư mục data/openvivqa để tương thích với cấu hình\n",
    "!mkdir -p data && cp -r /kaggle/working/OpenViVQA data/openvivqa || true\n",
    "\n",
    "# Kiểm tra thư mục dữ liệu\n",
    "!ls data/openvivqa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337d4df5",
   "metadata": {},
   "source": [
    "### Dữ liệu mẫu (tuỳ chọn)\n",
    "\n",
    "Nếu bạn chỉ muốn chạy thử nghiệm nhanh hoặc không có đủ tài nguyên GPU,\n",
    "script `scripts/create_sample_data.py` có thể tạo bộ dữ liệu nhỏ với vài ảnh\n",
    "màu cơ bản. Bạn có thể sử dụng cấu hình mẫu trong `config.py` (`SAMPLE_CONFIG`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65185310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo dữ liệu mẫu (tuỳ chọn)\n",
    "!python scripts/create_sample_data.py --output_dir sample_data\n",
    "\n",
    "# Kiểm tra dữ liệu mẫu\n",
    "!ls sample_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5b51ee",
   "metadata": {},
   "source": [
    "## 4. Huấn luyện mô hình\n",
    "\n",
    "Sử dụng script `main.py` (wrapper) để huấn luyện mô hình. Bạn có thể chọn giữa cấu\n",
    "hình đầy đủ (`FULL_CONFIG`) và cấu hình mẫu (`SAMPLE_CONFIG`) được định nghĩa\n",
    "trong `config.py` bằng tham số `--config`. Trong ví dụ dưới đây chúng ta sử dụng\n",
    "cấu hình mẫu để rút ngắn thời gian chạy. Để huấn luyện trên dữ liệu thật, thay thế `sample` bằng `full`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a824a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huấn luyện mô hình bằng config mẫu (chạy ~vài phút trên GPU)\n",
    "!python main.py --config sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9c798e",
   "metadata": {},
   "source": [
    "## 5. Đánh giá mô hình trên tập kiểm tra\n",
    "\n",
    "Sau khi huấn luyện xong, mô hình và tokenizer sẽ được lưu trong thư mục `output_dir`\n",
    "theo cấu hình. Dưới đây là ví dụ gọi lại huấn luyện viên để sinh câu trả\n",
    "lời và tính toán các chỉ số đánh giá sử dụng hàm `compute_vqa_metrics`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e3519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from openvivqa.evaluation.metrics import compute_vqa_metrics\n",
    "import torch\n",
    "\n",
    "# Cấu hình đường dẫn theo output_dir trong config\n",
    "output_dir = Path('sample_results')  # hoặc 'vit5-vqa-results' nếu dùng cấu hình full\n",
    "model_dir = output_dir / 'checkpoint-best'\n",
    "\n",
    "# Load mô hình (tokenizer nằm trong model_dir)\n",
    "from openvivqa.models import ViT5VQAModel\n",
    "model = ViT5VQAModel.from_pretrained(model_dir)\n",
    "tokenizer = model.tokenizer\n",
    "model.eval()\n",
    "\n",
    "# Load dữ liệu test\n",
    "test_data = json.load(open('sample_data/test.json'))\n",
    "\n",
    "preds, labels = [], []\n",
    "for item in test_data:\n",
    "    question = item['question']\n",
    "    answer = item['answer']\n",
    "    # Bạn cần trích xuất đặc trưng ảnh phù hợp với pipeline (bỏ qua trong ví dụ này)\n",
    "    # Ở đây chúng ta giả sử ảnh đã được xử lý hoặc sử dụng placeholder\n",
    "    raise NotImplementedError('Cần triển khai xử lý ảnh cho dữ liệu thực để sinh câu trả lời')\n",
    "\n",
    "# Khi có preds và labels, gọi:\n",
    "# metrics = compute_vqa_metrics(preds, labels)\n",
    "# print(metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
